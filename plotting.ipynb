{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec02391-1f58-4823-ba31-6fa3c2540535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16e60bd-c8f2-48ef-a6fc-3c3d2b4d2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daee9931-60ad-4113-a040-151d0422df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"Simple tokenizer that splits on spaces.\"\"\"\n",
    "    return clean_text(text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7ccbfc-56fe-429c-bf9e-20ff89df1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], vocab: dict, max_length: int):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        tokens = tokenize(text)\n",
    "        token_ids = [self.vocab.get(token, self.vocab['<unk>']) for token in tokens]\n",
    "        \n",
    "        # Truncate or pad sequence\n",
    "        if len(token_ids) > self.max_length:\n",
    "            token_ids = token_ids[:self.max_length]\n",
    "        else:\n",
    "            padding = [self.vocab['<pad>']] * (self.max_length - len(token_ids))\n",
    "            token_ids.extend(padding)\n",
    "        \n",
    "        return torch.tensor(token_ids), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cffcfea7-ce83-4498-b73b-b10758fd151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts: List[str], min_freq: int = 5) -> dict:\n",
    "    \"\"\"Build vocabulary from texts.\"\"\"\n",
    "    counter = Counter()\n",
    "    \n",
    "    for text in tqdm(texts, desc=\"Building vocabulary\"):\n",
    "        tokens = tokenize(text)\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    idx = len(vocab)\n",
    "    \n",
    "    for token, count in counter.most_common():\n",
    "        if count >= min_freq:\n",
    "            vocab[token] = idx\n",
    "            idx += 1\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ab790d-7baa-4992-91d8-9875f6c7986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Linear transformations\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "        \n",
    "        # Split into heads\n",
    "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        attention = self.dropout(attention)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        context = torch.matmul(attention, V)\n",
    "        \n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        # Final linear layer\n",
    "        output = self.W_o(context)\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebe1e6f-fcf9-4d80-9b38-dd3221337b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # Stack of encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        \n",
    "        # Embed and add positional encoding\n",
    "        x = self.embedding(x)  # (batch_size, seq_len, d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Store attention weights from all layers\n",
    "        attention_weights = []\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        for layer in self.layers:\n",
    "            x, attn = layer(x, mask)\n",
    "            attention_weights.append(attn)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Return output and attention weights\n",
    "        return x, attention_weights\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Self attention block\n",
    "        attn_output, attention_weights = self.self_attn(x, mask=mask)\n",
    "        x = x + self.dropout1(attn_output)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # Feed forward block\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        return x, attention_weights\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:x.size(0)].transpose(0, 1)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class SentimentTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, num_heads=8, num_layers=6, \n",
    "                 d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(\n",
    "            vocab_size, d_model, num_heads, num_layers, d_ff, dropout\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Encode the input sequence\n",
    "        encoded, attention_weights = self.encoder(x, mask)\n",
    "        \n",
    "        # Global average pooling\n",
    "        encoded = encoded.mean(dim=1)  # Average over sequence length\n",
    "        \n",
    "        # Classify\n",
    "        output = self.classifier(encoded)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8a5ca9-4bc7-4430-87c5-c00bab9df604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_attention_heatmap(attention_weights: torch.Tensor, \n",
    "                             layer_idx: int, \n",
    "                             head_idx: int, \n",
    "                             tokens: Optional[List[str]] = None,\n",
    "                             save_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Plots attention heatmap for a specific layer and head.\n",
    "        \"\"\"\n",
    "        # Get attention weights for specified layer and head\n",
    "        attention = attention_weights[layer_idx][0, head_idx].detach().cpu().numpy()\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Plot heatmap\n",
    "        if tokens:\n",
    "            # Truncate attention matrix to actual tokens length\n",
    "            attention = attention[:len(tokens), :len(tokens)]\n",
    "            sns.heatmap(attention, cmap=\"viridis\", xticklabels=tokens, yticklabels=tokens)\n",
    "        else:\n",
    "            sns.heatmap(attention, cmap=\"viridis\")\n",
    "            \n",
    "        plt.title(f\"Attention Weights - Layer {layer_idx + 1}, Head {head_idx + 1}\")\n",
    "        plt.xlabel(\"Key Positions\")\n",
    "        plt.ylabel(\"Query Positions\")\n",
    "        \n",
    "        # Rotate x-axis labels if tokens are provided\n",
    "        if tokens:\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "        \n",
    "        # Adjust layout to prevent label cutoff\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_all_attention_heads(attention_weights: List[torch.Tensor], \n",
    "                                    tokens: Optional[List[str]] = None,\n",
    "                                    save_dir: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Visualizes attention patterns for all layers and heads.\n",
    "        \"\"\"\n",
    "        num_layers = len(attention_weights)\n",
    "        num_heads = attention_weights[0].size(1)\n",
    "        \n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        for layer in range(num_layers):\n",
    "            for head in range(num_heads):\n",
    "                save_path = None\n",
    "                if save_dir:\n",
    "                    save_path = os.path.join(save_dir, f'attention_layer{layer+1}_head{head+1}.png')\n",
    "                AttentionVisualizer.plot_attention_heatmap(\n",
    "                    attention_weights, layer, head, tokens, save_path\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b10fc7-5f97-474a-bf0c-822975a22a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(model: nn.Module, \n",
    "                text: str, \n",
    "                vocab: dict, \n",
    "                max_length: int, \n",
    "                device: torch.device,\n",
    "                visualize: bool = True,\n",
    "                save_dir: Optional[str] = None) -> Tuple[str, float, List[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Analyzes a text sample and optionally visualizes its attention patterns.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing (prediction label, confidence score, attention weights)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and encode\n",
    "    tokens = tokenize(text)\n",
    "    token_ids = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "    \n",
    "    # Truncate or pad sequence\n",
    "    if len(token_ids) > max_length:\n",
    "        token_ids = token_ids[:max_length]\n",
    "        tokens = tokens[:max_length]\n",
    "    else:\n",
    "        padding_length = max_length - len(token_ids)\n",
    "        token_ids.extend([vocab['<pad>']] * padding_length)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        sequence = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "        mask = (sequence != 0).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        outputs, attention_weights = model(sequence, mask)\n",
    "        prediction = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get prediction details\n",
    "        pred_class = torch.argmax(prediction).item()\n",
    "        pred_prob = prediction[0][pred_class].item()\n",
    "        sentiment = \"Positive\" if pred_class == 1 else \"Negative\"\n",
    "        \n",
    "        # Visualize if requested\n",
    "        if visualize:\n",
    "            print(f\"\\nAnalyzing text: {text}\")\n",
    "            print(f\"Prediction: {sentiment} (confidence: {pred_prob:.2f})\")\n",
    "            print(\"\\nGenerating attention visualizations...\")\n",
    "            \n",
    "            AttentionVisualizer.visualize_all_attention_heads(\n",
    "                attention_weights, \n",
    "                tokens,\n",
    "                save_dir\n",
    "            )\n",
    "        \n",
    "        return sentiment, pred_prob, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83227dee-7d36-4bdf-a53a-be726cac83f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Building vocabulary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocabulary: 100%|██████████████████████████████████████████████████████| 50000/50000 [00:05<00:00, 9081.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 39412\n",
      "\n",
      "Analyzing text: This movie was absolutely fantastic! The acting was superb and the story was engaging throughout.\n",
      "Prediction: Positive (confidence: 0.58)\n",
      "\n",
      "Generating attention visualizations...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Configuration\n",
    "    MAX_LENGTH = 256\n",
    "    BATCH_SIZE = 32\n",
    "    D_MODEL = 256\n",
    "    NUM_HEADS = 8\n",
    "    NUM_LAYERS = 1\n",
    "    D_FF = 1024\n",
    "    DROPOUT = 0.1\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_EPOCHS = 1\n",
    "    MIN_FREQ = 5\n",
    "    TRAIN_RATIO = 0.8\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load and prepare data\n",
    "    df = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "    texts = df['review'].tolist()\n",
    "    labels = (df['sentiment'] == 'positive').astype(int).tolist()\n",
    "    \n",
    "    # Build vocabulary\n",
    "    print(\"Building vocabulary...\")\n",
    "    vocab = build_vocab(texts, min_freq=MIN_FREQ)\n",
    "    vocab_size = len(vocab)\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "    \n",
    "    # Create and train model\n",
    "    model = SentimentTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        d_ff=D_FF,\n",
    "        dropout=DROPOUT\n",
    "    ).to(device)\n",
    "    \n",
    "    # Example usage after training\n",
    "    sample_text = \"This movie was absolutely fantastic! The acting was superb and the story was engaging throughout.\"\n",
    "    \n",
    "    # Analyze text and visualize attention\n",
    "    sentiment, confidence, attention_weights = analyze_text(\n",
    "        model=model,\n",
    "        text=sample_text,\n",
    "        vocab=vocab,\n",
    "        max_length=MAX_LENGTH,\n",
    "        device=device,\n",
    "        visualize=True,\n",
    "        save_dir='attention_plots'\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ff8a5-7e90-4666-bda5-8cdfc07a506f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f40bb3-1b55-4659-bae7-db78a5599336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
